---
title: "3meta BRMS"
author: "Shari Liu"
date: "2/22/2022"
output: 
  html_document:
    code_folding: show
---

```{r setup, include=FALSE}
options(scipen = 999, digits = 4)
knitr::opts_chunk$set(comment = "#", echo = FALSE)
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"

options(repos = r)

## load required packages
ipak <- function (pkg) {
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <-
  c(
    "tidyverse",
    "lsmeans",
    "influence.ME",
    "lme4",
    "effects",
    "lmerTest",
    "cowplot",
    "irr",
    "simr",
    "patchwork",
    "wesanderson",
    "devtools",
    "effectsize",
    "mice",
    "rstan",
    "brms",
    "bayestestR",
    "rstanarm",
    "shinystan",
    "DT",
    "tidybayes",
    "distributional",
    "loo"
  )
devtools::install_github("mvuorre/brmstools")

ipak(packages)
set.seed(429)

# set summed contrasts
options(contrasts = c("contr.sum", "contr.poly"))

# fix bs with dplyr
detach("package:dplyr", unload = TRUE)
library("dplyr")

sessionInfo()
```

```{r}
ind.data.init <- read.csv("./fulldata.csv", header = TRUE)
str(ind.data.init)
num_cols <- c("ageday", "exp_look", "unexp_look", "look_pref")
factor_cols <- setdiff(colnames(ind.data.init), num_cols)

ind.data <- ind.data.init %>%
  mutate_at(factor_cols, as.factor)
str(ind.data)

constraints <- ind.data %>% filter(task == "constraints")
goals <- ind.data %>% filter(task == "goals")
constraints <- ind.data %>% filter(task == "constraints")

# checking ref levels for all factors
constraints$actor_hand <-
  factor(constraints$actor_hand, levels = c("bare", "gloved", "mittened")) # for summed contr last level is dropped
constraints$action_consequence <-
  relevel(constraints$action_consequence, ref = "state_change")
constraints$agent_efficient_fam <-
  relevel(constraints$agent_efficient_fam, ref = "yes")
constraints$training_yesno <-
  relevel(constraints$training_yesno, ref = "yes")
constraints$action_causal <-
  relevel(constraints$action_causal, ref = "yes")

goals$action_consequence <-
  relevel(goals$action_consequence, ref = "none")
goals$agent <-
  factor(goals$agent, levels = c("animate", "person", "hand")) # last level gets dropped in model estimates
goals$training_yesno <- relevel(goals$training_yesno, ref = "yes")
goals$bothobjects_present_visible_fam <-
  relevel(goals$bothobjects_present_visible_fam, ref = "yes")
```


# Exploratory Analysis
## Various attempts to make the frequentist setting work (not successful)
```{r, eval=FALSE}


# trying to figure out whether random slopes are possible in the frequentist setting
constraints.e1 <- lmer(
  data = constraints,
  formula = look_pref ~  training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + scale(ageday)  + (1 +
                                                                                                                                      experiment | paper),
  control = lmerControl(optimizer = "bobyqa")
)

summary(constraints.e1)


cooks.constraints.e1 <-
  cooks.distance(constraints.e1, group = "subj")
dotplot_diag(
  x = cooks.constraints.e1,
  cutoff = "internal",
  name = "cooks.distance",
  index = constraints$subj
) + ylab("Cook's distance") + xlab("subjID")

constraints.e1.cooks <-
  constraints[which(cooks.constraints.e1 <= 4 / 264), ]

constraints.e1.aftercooks <- lmer(
  data = constraints.e1.cooks,
  formula = look_pref ~  training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + scale(ageday)  + (1 +
                                                                                                                                      experiment | paper),
  control = lmerControl(optimizer = "bobyqa")
)

summary(constraints.e1.aftercooks)

# try other optimizers
constraints.e1.all <- allFit(constraints.e1)
summary(constraints.e1.all)
```

```{r, eval=FALSE}
constraints.full.e1 <- lmer(
  data = constraints,
  formula = look_pref ~  training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + scale(ageday) + (1 +
                                                                                                                                     experiment |
                                                                                                                                     paper),
  REML = FALSE,
  lmerControl(optimizer = "bobyqa")
) # REML set to false to enable model comparison via likelihood methods, change optimizer to Nelder Mead to deal with failures to converge

constraints.predictors = c(
  "training_yesno",
  "action_causal",
  "action_consequence",
  "actor_hand",
  "agent_efficient_fam",
  "ageday"
)

constraints.bf.e1 <- data.frame(constraints.predictors) %>%
  mutate(BF.cooks = NA,
         Interpretation.Cooks = NA) %>%
  rename(Fixed.Effect = constraints.predictors)

for (predictor in constraints.predictors) {
  modelform <-
    update(constraints.full.e1, as.formula(paste0(". ~ . -", predictor)))
  BF <- exp((BIC(modelform) - BIC(constraints.full.e1)) / 2)
  whichrow <-
    which(constraints.bf.e1$Fixed.Effect == as.character(predictor))
  constraints.bf.e1[whichrow, 2] <- BF
  constraints.bf.e1[whichrow, 3] <- interpret_bf(BF)
}

constraints.bf.e1
```

```{r, eval=FALSE}
# trying to figure out whether random slopes are possible in the frequentist setting
goals.e1 <- lmer(
  data = goals,
  formula = look_pref ~ training_yesno  + action_consequence + location_object_goal_ambiguous + agent + bothobjects_present_visible_fam +  scale(ageday)  + (1 +
                                                                                                                                                               experiment | paper),
  control = lmerControl(optimizer = "Nelder_Mead")
)

cooks.goals.e1 <- cooks.distance(goals.e1, group = "subj")
dotplot_diag(
  x = cooks.goals.e1,
  cutoff = "internal",
  name = "cooks.distance",
  index = goals$subj
) + ylab("Cook's distance") + xlab("subjID")

goals.e1.cooks <- goals[which(cooks.goals.e1 <= 4 / 386), ]

goals.e1.aftercooks <- lmer(
  data = goals.e1.cooks,
  formula = look_pref ~ training_yesno  + action_consequence + location_object_goal_ambiguous + agent + bothobjects_present_visible_fam +  scale(ageday)  + (1 +
                                                                                                                                                               experiment | paper),
  control = lmerControl(optimizer = "Nelder_Mead")
)

summary(goals.e1.aftercooks)
plot(allEffects(goals.e1.aftercooks))
```


## Attempts to original Sommerville data (on hold for now)
```{r}

# 0_pilotnotraining
# n = 16, mean age = 106.54
# UNEXP, M = 53.9, SD = 14.9
# EXP, M = 47.1, SD = 12.4

sommerville0.unexp <- rlnorm(16, meanlog=3.987, sdlog=.25)
mean(sommerville0.unexp)
sd(sommerville0.unexp)

sommerville0.exp <- rlnorm(16, meanlog=3.850, sdlog=.25)
mean(sommerville0.exp)
sd(sommerville0.exp)

# 1_watchfirst
# n = 15, mean age = 101.32
# UNEXP, M = 33.781, SD = 7.283212518
# EXP, M = 33.417, SD = 4.740388137
# t = 0.9

# 1_reachfirst
# n = 15, mean age = 104.32
# UNEXP, M = 53.992, SD = 11.10689909
# EXP, M = 30.504, SD = 4.369927511
# t = 2.6

```

## BRMS
In the primary analysis, we chose to pare down the random effects structure to just random intercepts for conditions, experiments, and papers, in order to deal with issues of convergence. Nevertheless, such an analytical choice neglects the correlated methodological decisions shared by conditions and experiments within papers, and leaves open the possibility that some of the effects we fit were driven by just a few conditions. When we explored ways of fitting frequentist models with alternative ways of specifying the random effects, and iteratively computing Bayes Factors like we did above, we never found a set of optimizers and random effects specifications that consistently converged. Thus, for an exploratory analysis we decided to refit the models from the confirmatory analysis with the full random effects structure using brms. 


```{r}
brms.test.hyp <- function(model, hyp.vector) {
  results <- hypothesis(model, hyp.vector, seed = 429, alpha = .05)
  return(results)
}

# function that returns formatted result from a brms.test.hyp df
report.brms <- function(df, index, places) {
  "Estimate = xx [xx, xx], Evidence Ratio = xx, Posterior Probability = xx"
  result <- paste(
    "Estimate = ",
    round(df$Estimate[index], places),
    " [",
    round(df$CI.Lower[index], places),
    ", ",
    round(df$CI.Upper[index], places),
    "], Evidence Ratio = ",
    round(df$Evid.Ratio[index], places),
    ", Posterior Probability = ",
    round(df$Post.Prob[index], places),
    sep = ""
  )
  return(result)
}
```

### Goals Task
```{r}
#  not run, uncomment to reproduce results
# goals.brms.intercept <- brm(formula = look_pref ~ 1 + ageday + (1|condition) + (1+condition|experiment) + (1+condition|paper),
#                 data= goals,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(goals.brms.intercept,file="goals.brms.intercept.rds")
goals.brms.intercept <- readRDS("goals.brms.intercept.rds")
# shinystan::launch_shinystan(goals.brms.intercept)
summary(goals.brms.intercept)
pp_check(goals.brms.intercept, ndraws = 10)
goals.brms.intercept.diag <- loo(goals.brms.intercept)
plot(goals.brms.intercept.diag)


goals.brms.intercept.results <-
  brms.test.hyp(goals.brms.intercept, "Intercept > 0")

goals_hypothesis_vector <- c(
  "ageday < 0",
  "training_yesno1 > 0",
  "location_object_goal_ambiguous1 > 0",
  "action_consequence1 > 0",
  "agent1 > 0",
  "agent2 > 0",
  "bothobjects_present_visible_fam1 > 0"
)

# goals.brms.full <- brm(formula = look_pref ~ training_yesno + agent + action_consequence + bothobjects_present_visible_fam + location_object_goal_ambiguous + ageday + (1|condition) + (1+condition|experiment) + (1+experiment|paper),
#                 data= goals,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(goals.brms.full,file="goals.brms.full.rds")
goals.brms.full <- readRDS("goals.brms.full.rds")
# shinystan::launch_shinystan(goals.brms.full)
summary(goals.brms.full)
pp_check(goals.brms.full, nsamples = 10)
goals.brms.full.diag <- loo(goals.brms.full)
plot(goals.brms.full.diag)


goals.brms.full.results <-
  brms.test.hyp(goals.brms.full, goals_hypothesis_vector)


# goals.brms.full.simplefx  <- brm(formula = look_pref ~ training_yesno + agent + action_consequence + bothobjects_present_visible_fam + location_object_goal_ambiguous + ageday + (1|condition) + (1|experiment) + (1|paper),
#                 data= goals,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(goals.brms.full.simplefx,file="goals.brms.full.simplefx.rds")
goals.brms.full.simplerfx <- readRDS("goals.brms.full.simplefx.rds")
# shinystan::launch_shinystan(goals.brms.full.simplerfx)
summary(goals.brms.full.simplerfx)
pp_check(goals.brms.full.simplerfx, ndraws = 10)
goals.brms.full.simplerfx.diag <- loo(goals.brms.full.simplerfx)
plot(goals.brms.full.simplerfx.diag)

goals.brms.full.simplerfx.results <-
  brms.test.hyp(goals.brms.full.simplerfx, goals_hypothesis_vector)

(goals.compare.rfx <-
    bayes_factor(goals.brms.full.simplerfx, goals.brms.full))
```


```{r}
knitr::kable(goals.brms.intercept.results[[1]])
knitr::kable(goals.brms.full.results[[1]])
knitr::kable(goals.brms.full.simplerfx.results[[1]])

```

The intercept only model (`look_pref ~ 1 + ageday + (1|condition) + (1+condition|experiment) + (1+condition|paper)`) provided moderate evidence for looking preference larger than 0 (evidence ratio = `r report.brms(goals.brms.intercept.results[[1]],1,3)`). The full model with complex random effects (`look_pref ~ training_yesno  + action_consequence + location_object_goal_ambiguous + agent + bothobjects_present_visible_fam + ageday + (1|condition) + (1+condition|experiment) + (1+experiment|paper)`)  yielded some similar results to the frequentist model, but also some differences: of all the predictors, there was moderate evidence that seeing unambiguous evidence for  someone’s goal `r report.brms(goals.brms.full.results[[1]],3,3)` mattered for infants' looking preferences, as did infant age `r report.brms(goals.brms.full.results[[1]],1,3)`, with older babies showing smaller effects than younger babies. These effects were substantially smaller than the full Bayesian model with simpler random effects, and all confidence intervals included 0, suggesting that substantial variance in the data is accounted for by shared methodological considerations within experiments and papers. As in the constraints task, the Bayes Factor between the full models with identical fixed effects and varying (simple vs complex) random effects strongly favored the simple random effects structure (BF = `r goals.compare.rfx[[1]]`). These results suggest that although adding random slopes for conditions and experiments accounted for variance in infants’ looking behavior, the simple random effects structure represented in the frequentist analysis better accounted for this data. In the Bayesian version of this model, the only effect with posterior probability greater than 0.95 was seeing unambiguous evidence for someone’s goal (`r report.brms(goals.brms.full.simplerfx.results[[1]],3,3)`), which largely agrees with the findings from the frequentist analysis. 


### Constraints Task
```{r}
hist(constraints$look_pref)

# #  not run, uncomment to reproduce results
# constraints.brms.intercept <- brm(formula = look_pref ~ 1 + ageday + (1|condition) + (1+condition|experiment) + (1+condition|paper),
#                 data= constraints,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(constraints.brms.intercept,file="constraints.brms.intercept.rds")


constraints.brms.intercept <-
  readRDS("constraints.brms.intercept.rds")
# shinystan::launch_shinystan(constraints.brms.intercept)
summary(constraints.brms.intercept)
pp_check(constraints.brms.intercept, ndraws = 100)
constraints.brms.intercept.diag <- loo(constraints.brms.intercept)
plot(constraints.brms.intercept.diag)

hypothesis(constraints.brms.intercept, "Intercept < 0", alpha = .05)

constraints_hypothesis_vector <- c(
  "ageday > 0",
  "training_yesno1 > 0",
  "action_causal1 > 0",
  "action_consequence1 > 0",
  "actor_hand1 > 0",
  "actor_hand2 > 0",
  "agent_efficient_fam1 > 0"
)

# constraints.brms.full <- brm(formula = look_pref ~ training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + ageday + (1|condition) + (1+condition|experiment) + (1|paper),
#                 data= constraints,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(constraints.brms.full,file="constraints.brms.full.rds")
constraints.brms.full <- readRDS("constraints.brms.full.rds")
pp_check(constraints.brms.full, ndraws=100)
# shinystan::launch_shinystan(constraints.brms.full)
summary(constraints.brms.full)
constraints.brms.full.diag <- loo(constraints.brms.full)
plot(constraints.brms.full.diag)

# constraints.brms.full.simplerfx <- brm(formula = look_pref ~ training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + ageday + (1|condition) + (1|experiment) + (1|paper),
#                 data= constraints,
#                 warmup = 1000,
#                 iter   = 5000,
#                 family = student(link="identity"),
#                 chains = 6,
#                 thin = 2,
#                 seed = 429,
#                 save_all_pars = TRUE,
#                 sample_prior = TRUE,
#                 control = list(adapt_delta = .98))
# saveRDS(constraints.brms.full.simplerfx,file="constraints.brms.full.simplerfx.rds")
constraints.brms.full.simplerfx <-
  readRDS("constraints.brms.full.simplerfx.rds")
# shinystan::launch_shinystan(constraints.brms.full.simplerfx)
constraints.brms.full.simplerfx.diag <-
  loo(constraints.brms.full.simplerfx)
plot(constraints.brms.full.simplerfx.diag)
pp_check(constraints.brms.full.simplerfx, ndraws = 100)
summary(constraints.brms.full.simplerfx)


constraints.brms.intercept.results <-
  brms.test.hyp(constraints.brms.intercept, "Intercept > 0")

constraints.brms.full.simplerfx.results <-
  brms.test.hyp(constraints.brms.full.simplerfx,
                constraints_hypothesis_vector)

constraints.brms.full.results <-
  brms.test.hyp(constraints.brms.full, constraints_hypothesis_vector)

(
  constraints.compare.rfx <-
    bayes_factor(constraints.brms.full.simplerfx, constraints.brms.full)
)

```

```{r}
knitr::kable(constraints.brms.intercept.results[[1]])
knitr::kable(constraints.brms.full.simplerfx.results[[1]])
knitr::kable(constraints.brms.full.results[[1]])
```

The intercept only model (`look_pref ~ 1 + ageday + (1|condition) + (1+condition|experiment) + (1+condition|paper)`) provided moderate against the hypothesis that there is a looking preference  than 0 `r report.brms(constraints.brms.intercept.results[[1]],1,3)`.  The full model with complex random effects (`look_pref ~ training_yesno + action_causal + action_consequence + actor_hand + agent_efficient_fam + ageday + (1|condition) + (1+condition|experiment) + (1+experiment|paper)`) yielded qualitatively similar results to the frequentist model (see Table x): of all the predictors, infant age (`r report.brms(constraints.brms.full.results[[1]],1,3)`), and seeing an action that caused an observable outcome on contact (`r report.brms(constraints.brms.full.results[[1]],3,3)`) had the highest predictive power on infants’ looking behavior, followed by a manipulation that picked out control conditions (`r report.brms(constraints.brms.full.results[[1]],7,3)`), and then sticky mittens training (`r report.brms(constraints.brms.full.results[[1]],2,3)`). However, like in the goals task, the confidence interval over these estimates included 0, and the size of the evidence ratios were substantially smaller than the Bayes Factors from the frequentist model, and smaller than the evidence ratios from the full Bayesian model with simpler random effects (see Table x), suggesting that substantial variance in the data is accounted for by shared methodological decisions within experiments and papers. (Note that the 26 conditions from this task came from just 2 papers). Nevertheless, the Bayes Factor between these two full models with identical fixed effects and varying (simple vs complex) random effects substantially favored the simple random effects structure (BF = `r constraints.compare.rfx[[1]]`). Altogether, these results suggest that although adding random slopes for conditions and experiments accounted for variance in infants’ looking behavior, simple random effects structure presented in the frequentist analysis better accounts for the data. (One caveat to this interpretation is that the number of conditions and papers were limited - only 2 papers with 7 and 5 conditions each.) In the Bayesian version of this model, the only effects with posterior probabilities greater than 0.95 were sticky mittens training (`r report.brms(constraints.brms.full.simplerfx.results[[1]],2,3)`), causal action (`r report.brms(constraints.brms.full.simplerfx.results[[1]],3,3)`), and seeing a constraint agent during habituation (`r report.brms(constraints.brms.full.simplerfx.results[[1]],7,3)`), which accord with the findings from the frequentist analysis.
